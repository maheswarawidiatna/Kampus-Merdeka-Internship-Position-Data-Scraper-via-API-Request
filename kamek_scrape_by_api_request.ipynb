{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **extraction**"
      ],
      "metadata": {
        "id": "EQPezBONQMS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://api.kampusmerdeka.kemdikbud.go.id/magang/browse/position\"\n",
        "limit = 100\n",
        "offset = 0\n",
        "\n",
        "all_data = pd.DataFrame()\n",
        "\n",
        "while True:\n",
        "    params = {\n",
        "        \"offset\": offset,\n",
        "        \"limit\": limit,\n",
        "        \"location_key\": \"\",\n",
        "        \"mitra_key\": \"\",\n",
        "        \"keyword\": \"\",\n",
        "        \"sector_id\": \"\",\n",
        "        \"sort_by\": \"published_time\",\n",
        "        \"order\": \"desc\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    offset += limit\n",
        "    data = pd.DataFrame(response.json()[\"data\"])\n",
        "    if len(data) == 0:\n",
        "        break\n",
        "    all_data = pd.concat([all_data, data], ignore_index=True)\n",
        "    print(f\"data collected : {len(all_data)}\")\n",
        "\n",
        "print(f\"{len(all_data)} data is collected\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1o7nOe4zXWN",
        "outputId": "a4acb20b-ec28-4377-a0f3-9e77b41d52be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data collected : 100\n",
            "data collected : 200\n",
            "data collected : 300\n",
            "data collected : 400\n",
            "data collected : 500\n",
            "data collected : 600\n",
            "data collected : 700\n",
            "data collected : 800\n",
            "data collected : 900\n",
            "data collected : 1000\n",
            "data collected : 1100\n",
            "data collected : 1200\n",
            "data collected : 1300\n",
            "data collected : 1400\n",
            "data collected : 1500\n",
            "data collected : 1600\n",
            "data collected : 1700\n",
            "data collected : 1800\n",
            "data collected : 1900\n",
            "data collected : 2000\n",
            "data collected : 2100\n",
            "data collected : 2200\n",
            "data collected : 2300\n",
            "data collected : 2400\n",
            "data collected : 2500\n",
            "data collected : 2600\n",
            "data collected : 2700\n",
            "data collected : 2800\n",
            "data collected : 2900\n",
            "data collected : 3000\n",
            "data collected : 3100\n",
            "data collected : 3200\n",
            "data collected : 3300\n",
            "data collected : 3400\n",
            "data collected : 3500\n",
            "data collected : 3600\n",
            "data collected : 3700\n",
            "data collected : 3800\n",
            "data collected : 3900\n",
            "data collected : 4000\n",
            "data collected : 4100\n",
            "data collected : 4200\n",
            "data collected : 4300\n",
            "data collected : 4400\n",
            "data collected : 4500\n",
            "data collected : 4600\n",
            "data collected : 4700\n",
            "data collected : 4800\n",
            "data collected : 4900\n",
            "data collected : 5000\n",
            "data collected : 5100\n",
            "data collected : 5200\n",
            "data collected : 5300\n",
            "data collected : 5400\n",
            "data collected : 5500\n",
            "data collected : 5509\n",
            "5509 data is collected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "hapus '#' diawal baris klo mau download all_data.xlsx"
      ],
      "metadata": {
        "id": "khmb5NzbQVt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "#all_data.to_excel('all_data.xlsx', index=False)\n",
        "#files.download('all_data.xlsx')"
      ],
      "metadata": {
        "id": "Bb6CCGKoLyNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **data processing**"
      ],
      "metadata": {
        "id": "x8Qwjz-UIQHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pilih mau perusahaan apa aja, korporat dan BUMN"
      ],
      "metadata": {
        "id": "Vuw5wzXiQhJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corp = ['Astra',\n",
        " 'BCA',\n",
        " 'Blibli.com',\n",
        " 'GoTo',\n",
        " 'Huawei',\n",
        " 'Lazada',\n",
        " 'MAP',\n",
        " 'Neobank',\n",
        " 'Paragon Technology and Innovation',\n",
        " 'Toyota Indonesia',\n",
        " 'Trakindo',\n",
        " 'Traveloka',\n",
        " 'United Tractors']\n",
        "\n",
        "bumn = [\n",
        " 'BNI',\n",
        " 'Bank BRI',\n",
        " 'Bank Syariah Indonesia atau BSI',\n",
        " 'Jasa Marga',\n",
        " 'Kampus Merdeka Bank Indonesia (KMBI)',\n",
        " 'PT Bank Mandiri (Persero) Tbk',\n",
        " 'PT INKA (Persero)',\n",
        " 'PT PLN (PERSERO)',\n",
        " 'PT Permodalan Nasional Madani',\n",
        " 'PT Pertamina (Persero)',\n",
        " 'PT Petrokimia Gresik',\n",
        " 'Telkom',\n",
        " 'Telkomsel',]"
      ],
      "metadata": {
        "id": "vkk8NGrC7UeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f_data = all_data[['name', 'activity_name', 'total', 'location', 'mitra_name']]"
      ],
      "metadata": {
        "id": "uboyKpfPBDX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def summarize(df, pr, output_filename):\n",
        "    temp = df[df['mitra_name'].isin(pr)]\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
        "        result = pd.DataFrame(columns=[\"company\", \"quota\", \"location\", \"activity\", \"job\"])\n",
        "\n",
        "        for company in set(temp[\"mitra_name\"]):\n",
        "            c_temp = temp[temp[\"mitra_name\"] == company]\n",
        "            sheet_name = company[:31]\n",
        "            c_temp.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "\n",
        "            avg_quota = c_temp[\"total\"].sum() / len(c_temp[\"name\"])\n",
        "            location = set(c_temp['location'])\n",
        "            activity = set(c_temp['activity_name'])\n",
        "            job = set(c_temp['name'])\n",
        "\n",
        "            result = pd.concat([result, pd.DataFrame({\"company\": [company], \"quota\": [avg_quota], \"location\": [location], 'activity': [activity], 'job': [job]})], ignore_index=True)\n",
        "\n",
        "        result = result.sort_values(by=\"quota\", ascending=False).reset_index(drop=True)\n",
        "        result.index = result.index + 1\n",
        "\n",
        "        left = set(df['mitra_name']) - set(pr)\n",
        "\n",
        "        result.to_excel(writer, sheet_name='Summary', index=False)\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "aY_GUDXWK5aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_corp = summarize(f_data, corp, 'corp_sum.xlsx')\n",
        "summary_bumn = summarize(f_data, bumn, 'bumn_sum.xlsx')\n",
        "\n",
        "files.download('corp_sum.xlsx')\n",
        "files.download('bumn_sum.xlsx')"
      ],
      "metadata": {
        "id": "b-FF10nQ93qf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "bcbd8866-821f-44f5-8e35-f40594551523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d82601ea-4ed8-41fb-99c3-f9e44123fba4\", \"corpsum.xlsx\", 43988)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c0f48b9c-5165-4753-8949-c6d9250059c3\", \"bumnsum.xlsx\", 50795)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}